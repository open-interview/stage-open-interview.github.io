{"questions":[{"id":"q-448","question":"Explain how process scheduling works in an operating system. Which scheduling algorithm would you choose for a real-time system and why?","answer":"Process scheduling manages CPU allocation among processes. For real-time systems, I'd use **Rate Monotonic Scheduling (RMS)** because it's predictable, has bounded response times, and is optimal for f","explanation":"## Key Concepts\n- **Process scheduling**: Decides which process gets CPU time\n- **Scheduling algorithms**: FCFS, SJF, Priority, Round Robin, RMS\n- **Real-time requirements**: Deterministic timing, deadline guarantees\n\n## Real-time Considerations\n- **Predictability**: Must guarantee task completion before deadlines\n- **Priority assignment**: Shorter periods get higher priorities\n- **CPU utilization**: RMS can utilize up to 69% of CPU safely\n\n## Implementation\n```c\n// RMS priority calculation\npriority = 1000 / period; // Higher for shorter periods\n```\n\n## Trade-offs\n- RMS is simple but less flexible than EDF\n- Requires periodic task characteristics\n- Bounded utilization prevents overload","diagram":"flowchart TD\n  A[Process Request] --> B{Scheduler}\n  B --> C[RMS Priority Check]\n  C --> D[CPU Allocation]\n  D --> E[Process Execution]\n  E --> F[Deadline Check]\n  F --> G{Met Deadline?}\n  G -->|Yes| H[Continue]\n  G -->|No| I[Priority Boost]\n  H --> B","difficulty":"beginner","tags":["operating-systems"],"channel":"operating-systems","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","OpenAI","Snap"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-24T02:40:25.205Z","createdAt":"2025-12-25 12:50:54"},{"id":"q-471","question":"You're designing a GPU memory manager for CUDA applications. How would you implement a memory allocator that handles both unified memory and explicit device memory, considering fragmentation, coalescing, and the 48-bit address space limitations?","answer":"Implement a hybrid allocator using segregated free lists for different size classes, with a buddy system for large allocations. Use virtual memory techniques to handle the 48-bit address space, implem","explanation":"## Memory Management Architecture\n\n### Allocation Strategies\n- **Segregated lists**: Separate free lists for small (4KB-64KB), medium (64KB-1MB), large (>1MB) allocations\n- **Buddy system**: Power-of-2 allocation for large blocks to enable efficient coalescing\n- **Slab allocation**: For frequently used small objects to reduce fragmentation\n\n### Address Space Management\n```c\n// 48-bit virtual address layout\ntypedef struct {\n    uint64_t prefix : 16;  // Reserved for future expansion\n    uint64_t vaddr   : 48;  // Actual virtual address\n} gpu_vaddr_t;\n```\n\n### Unified Memory Optimization\n- **Migration policies**: Implement read-mostly and write-mostly heuristics\n- **Prefetching**: Based on access pattern analysis and memory bandwidth\n- **Page granularity**: Use 2MB pages for large contiguous regions\n\n### Performance Considerations\n- **Fragmentation control**: Implement compaction during idle periods\n- **Lock-free operations**: Use atomic operations for allocation metadata\n- **NUMA awareness**: Consider GPU topology for multi-GPU systems","diagram":"flowchart TD\n  A[Application Request] --> B{Memory Type}\n  B -->|Unified| C[Unified Memory Path]\n  B -->|Device| D[Explicit Device Memory]\n  C --> E[Page Fault Handler]\n  E --> F[Migration Heuristics]\n  F --> G[Allocate Virtual Pages]\n  D --> H[Size Class Selection]\n  H --> I[Segregated Free List]\n  I --> J[Buddy System Check]\n  J --> K[Physical Allocation]\n  G --> L[GPU Memory Mapping]\n  K --> L","difficulty":"advanced","tags":["operating-systems"],"channel":"operating-systems","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","NVIDIA"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-24T02:47:40.232Z","createdAt":"2025-12-25 12:50:55"},{"id":"q-263","question":"How does demand paging improve memory efficiency in virtual memory systems, and what triggers a page fault?","answer":"Pages load only when accessed via page faults, avoiding unnecessary memory allocation and improving system performance.","explanation":"## Why Asked\nTests understanding of virtual memory management, a core OS concept for memory optimization and system performance.\n\n## Key Concepts\n- Demand paging vs pre-paging\n- Page fault handling mechanism\n- Memory management unit (MMU)\n- Page replacement algorithms\n- Working set theory\n\n## Code Example\n```\n// Page fault handler pseudocode\nvoid handle_page_fault(int address) {\n  int page_num = address / PAGE_SIZE;\n  if (page_table[page_num].valid_bit == 0) {\n    load_page_from_disk(page_num);\n    page_table[page_num].valid_bit = 1;\n  }\n  restart_instruction();\n}\n```\n\n## Follow-up Questions\n- How does the OS choose which pages to evict?\n- What's the difference between hard and soft page faults?\n- How does demand paging relate to thrashing?","diagram":"flowchart TD\n    A[Process accesses memory] --> B{Page in RAM?}\n    B -->|Yes| C[Access data directly]\n    B -->|No| D[Page fault triggered]\n    D --> E[OS handles fault]\n    E --> F[Load page from disk]\n    F --> G[Update page table]\n    G --> H[Restart instruction]\n    H --> C","difficulty":"intermediate","tags":["virtual-memory","paging","segmentation","cache"],"channel":"operating-systems","subChannel":"memory","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=OSvInZRS4og","longVideo":null},"companies":["Amazon","Apple","Google","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T13:05:40.226Z","createdAt":"2025-12-25 12:50:54"}],"subChannels":["general","memory"],"companies":["Amazon","Apple","DoorDash","Google","Meta","Microsoft","NVIDIA","OpenAI","Snap"],"stats":{"total":3,"beginner":1,"intermediate":1,"advanced":1,"newThisWeek":3}}
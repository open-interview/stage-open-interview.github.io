{"questions":[{"id":"q-168","question":"What is the CSS 'box model' and what are its four main components?","answer":"The CSS box model consists of content, padding, border, and margin that surround every HTML element.","explanation":"## Core Components\nEvery HTML element has four layers: content (text/images), padding (space inside border), border (edge around padding), and margin (space outside border).\n\n## Box-Sizing Property\n- `content-box` (default): width/height = content only\n- `border-box`: width/height = content + padding + border\nBorder-box is preferred for predictable layouts.\n\n## Margin Collapsing\nVertical margins collapse when:\n- Adjacent siblings (larger margin wins)\n- Parent and first/last child\n- Empty elements\nHorizontal margins never collapse.\n\n## Visual vs Layout Models\nVisual box model (dev tools) shows all layers. Layout model affects element positioning and sizing. Use `box-sizing: border-box` for intuitive responsive design.","diagram":"graph TD\n    A[Margin] --> B[Border]\n    B --> C[Padding]\n    C --> D[Content]\n    style A fill:#f9f9f9,stroke:#333\n    style B fill:#e6f3ff,stroke:#333\n    style C fill:#ffe6e6,stroke:#333\n    style D fill:#e6ffe6,stroke:#333","difficulty":"beginner","tags":["css","styling"],"channel":"frontend","subChannel":"css","sourceUrl":null,"videos":null,"companies":null,"eli5":"Imagine your HTML element is like a sandwich! The content is the yummy filling in the middle - that's your text or picture. The padding is like the soft bread around your filling, giving it some comfy space. The border is like the crust of your sandwich - it's the edge that holds everything together. The margin is like the empty plate around your sandwich, keeping it from touching other food on the table. Every element on a webpage gets its own little sandwich with all these layers!","relevanceScore":83,"lastUpdated":"2025-12-24T06:26:44.473Z","createdAt":"2025-12-23 12:53:10"},{"id":"q-363","question":"You have a navigation bar with 3 items that should be evenly spaced. The middle item needs to be centered while the first and last items stick to the edges. How would you implement this using CSS Flexbox?","answer":"Use justify-content: space-between on the container, and set the middle item to margin: 0 auto or position it absolutely centered.","explanation":"## Why This Is Asked\nTests fundamental Flexbox understanding and practical layout skills that are essential for frontend development at HRT.\n\n## Expected Answer\nCandidate should explain justify-content: space-between distributes outer items to edges, then discuss centering the middle item using margin: 0 auto or flex: 1 with text-align: center.\n\n## Code Example\n```css\n.nav {\n  display: flex;\n  justify-content: space-between;\n  align-items: center;\n}\n.nav-item:first-child,\n.nav-item:last-child {\n  flex: 0 0 auto;\n}\n.nav-item:nth-child(2) {\n  margin: 0 auto;\n}\n```\n\n## Follow-up Questions\n- How would you solve this using CSS Grid instead?\n- What happens when the viewport is too narrow?\n- Can you think of an alternative approach using position absolute?","diagram":"flowchart TD\n  A[Flex Container] --> B[justify-content: space-between]\n  B --> C[First Item â†’ flex: 0 0 auto]\n  B --> D[Last Item â†’ flex: 0 0 auto]\n  B --> E[Middle Item â†’ margin: 0 auto]\n  C --> F[Sticks to left edge]\n  D --> G[Sticks to right edge]\n  E --> H[Centered between edges]","difficulty":"beginner","tags":["css","flexbox","grid","animations"],"channel":"frontend","subChannel":"css","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","Hrt","Meta","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T16:40:31.787Z","createdAt":"2025-12-23 12:53:09"},{"id":"q-408","question":"You're building a responsive dashboard with a complex grid layout that must support dynamic widget resizing, reordering via drag-and-drop, and maintain performance with 100+ widgets. How would you architect the CSS grid system to handle these requirements while ensuring smooth animations and preventing layout thrashing?","answer":"Use CSS Grid with CSS custom properties for dynamic sizing, CSS transforms for animations, and virtualization for performance.","explanation":"## Why This Is Asked\nOkta needs engineers who can build complex, performant UIs at scale. This tests understanding of CSS Grid architecture, performance optimization, and real-world dashboard challenges.\n\n## Expected Answer\nStrong candidates will discuss: CSS Grid with custom properties for dynamic sizing, transform-based animations to avoid layout thrashing, virtualization techniques for large widget counts, and fallback strategies for older browsers.\n\n## Code Example\n```css\n.dashboard {\n  display: grid;\n  grid-template-columns: repeat(var(--cols, 12), 1fr);\n  gap: var(--gap, 16px);\n  will-change: transform;\n}\n\n.widget {\n  grid-column: span var(--span, 3);\n  transform: translate3d(0, 0, 0);\n  transition: transform 0.2s ease;\n}\n\n.widget.dragging {\n  z-index: 1000;\n  transform: scale(1.05) translate3d(0, 0, 0);\n}\n```\n\n## Follow-up Questions\n- How would you handle widget persistence across page refreshes?\n- What strategies would you use to minimize reflow during drag operations?\n- How would you implement responsive breakpoints for different screen sizes?","diagram":"flowchart TD\n  A[CSS Grid Container] --> B[Custom Properties Setup]\n  B --> C[Widget Grid Areas]\n  C --> D[Drag-Drop Handler]\n  D --> E{Transform Update?}\n  E -->|Yes| F[GPU Accelerated Animation]\n  E -->|No| G[Grid Property Update]\n  F --> H[Virtualization Check]\n  G --> H\n  H --> I[Performance Monitor]\n  I --> J[Layout Stabilization]","difficulty":"advanced","tags":["css","flexbox","grid","animations"],"channel":"frontend","subChannel":"css","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Affirm","Okta","Shopify"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T12:52:31.014Z","createdAt":"2025-12-23 12:53:09"},{"id":"fe-2","question":"Explain the JavaScript Event Loop architecture. How do microtasks and macrotasks differ in execution order, and what are the practical implications for async/await code?","answer":"The Event Loop manages execution by processing all microtasks (Promise callbacks, async/await) between each macrotask (setTimeout, DOM events). Microtasks have higher priority, executing immediately after the current script completes, while macrotasks queue for the next tick. This affects async/await behavior where await creates microtask scheduling.","explanation":"## Interview Context\nThis question tests understanding of JavaScript's concurrency model and its impact on application performance. Senior developers must grasp event loop mechanics to optimize responsive applications.\n\n## Key Concepts\n- **Microtasks**: Promise.then/catch/finally, async/await continuation, MutationObserver, queueMicrotask()\n- **Macrotasks**: setTimeout, setInterval, DOM events, requestAnimationFrame, I/O operations\n- **Execution Order**: Each macrotask completes â†’ process all microtasks â†’ render â†’ next macrotask\n\n## Code Example\n```javascript\nconsole.log('1');\nsetTimeout(() => console.log('2'), 0);\nPromise.resolve().then(() => console.log('3'));\nconsole.log('4');\n// Output: 1, 4, 3, 2\n```\n\n## Performance Implications\n- Microtask starvation: Excessive microtasks block UI rendering\n- Batch DOM updates using requestAnimationFrame for smooth 60fps\n- Use Web Workers for CPU-intensive tasks to prevent main thread blocking\n- Node.js event loop differs: nextTick vs setImmediate priority\n\n## Follow-up Questions\n- How would you debug microtask queue starvation in production?\n- What's the difference between requestAnimationFrame and setTimeout for animations?\n- How does async/await transform into microtasks under the hood?","diagram":"\ngraph TD\n    Stack[Call Stack] -->|Empty?| CheckMicro{Microtasks?}\n    CheckMicro -->|Yes| RunMicro[Run All Microtasks]\n    RunMicro --> CheckMicro\n    CheckMicro -->|No| Render[Render UI]\n    Render --> RunMacro[Run One Macrotask]\n    RunMacro --> Stack\n","difficulty":"beginner","tags":["js","async","core"],"channel":"frontend","subChannel":"javascript","sourceUrl":null,"videos":null,"companies":null,"eli5":"Imagine you're playing with toys! The Event Loop is like a toy manager. You have one special box (the main work) that you can only play with one toy at a time. Sometimes toys need to wait for things (like baking cookies), so they go to different waiting lines. Microtasks are like quick snacks - small, yummy bites you eat right away before anything else. Macrotasks are like big meals - important but take more time, so you wait until all snacks are done. The toy manager always checks for snacks first, then big meals, making sure everything gets played with in the right order!","relevanceScore":null,"lastUpdated":"2025-12-24T12:40:17.709Z","createdAt":"2025-12-23 12:53:09"},{"id":"fe-3","question":"Explain JavaScript closures with a practical use case and how they're used in real applications?","answer":"A closure is a function that retains access to its lexical scope, allowing it to use variables from its outer function even after that function has returned.","explanation":"## Why Asked\nTesting understanding of JavaScript's execution context and memory management\n## Key Concepts\nLexical scoping, function scope, memory retention, callbacks, module pattern\n## Code Example\n```\nfunction createCounter() {\n  let count = 0;\n  return function() {\n    count++;\n    return count;\n  };\n}\nconst counter = createCounter();\nconsole.log(counter()); // 1\nconsole.log(counter()); // 2\n```\n## Follow-up Questions\nWhat's the memory impact of closures? How do they relate to garbage collection? Can you explain closure optimization?","diagram":"flowchart TD\n  A[Outer Function Called] --> B[Inner Function Created]\n  B --> C[Outer Function Returns]\n  C --> D[Inner Function Accesses Outer Variables]\n  D --> E[Closure Maintains Scope Chain]","difficulty":"intermediate","tags":["js","scope","patterns"],"channel":"frontend","subChannel":"javascript","sourceUrl":null,"videos":{"shortVideo":"https://youtube.com/watch?v=8SlpmJOhoKA","longVideo":"https://youtube.com/watch?v=beZfCfiuIkA"},"companies":["Amazon","Google","Meta"],"eli5":"Imagine you have a magic backpack that remembers all your toys even when you leave the playground. A closure is like that backpack - it's a special function that keeps all the toys (variables) from where it was born, even when it goes to play somewhere else. Think of it like a cookie jar that remembers which cookies were inside when you made it. When you need cookies later, the jar still has them! Real apps use this all the time - like when a game remembers your score even when you switch screens, or when a website remembers your name after you type it in. The magic backpack just carries everything with it wherever it goes!","relevanceScore":null,"lastUpdated":"2025-12-22T08:33:29.210Z","createdAt":"2025-12-23 12:53:08"},{"id":"fr-157","question":"What is the difference between `let`, `const`, and `var` in JavaScript, and how do their scoping rules and temporal dead zone affect real-world code?","answer":"`var` is function-scoped and hoisted with `undefined` initialization. `let` and `const` are block-scoped with temporal dead zone - they exist but can't be accessed before declaration. `const` prevents reassignment (not immutability). Use `const` by default, `let` when reassignment is needed, and avoid `var` in modern code.","explanation":"## Scoping Differences\n`var` is function-scoped and accessible throughout the entire function, regardless of block boundaries. `let` and `const` are block-scoped, limited to `{}` blocks, loops, and conditionals.\n\n## Temporal Dead Zone\n`let` and `const` exist in their scope from the start but can't be accessed until declared - this is the temporal dead zone. `var` is hoisted and initialized as `undefined`.\n\n## Practical Examples\n```javascript\n// var - function scoped\nfunction test() {\n  if (true) {\n    var x = 1;\n  }\n  console.log(x); // 1 - accessible outside block\n}\n\n// let/const - block scoped\nfunction test() {\n  if (true) {\n    let y = 1;\n  }\n  console.log(y); // ReferenceError - not accessible\n}\n\n// Temporal dead zone\nconsole.log(z); // undefined (var)\nvar z = 1;\n\nconsole.log(w); // ReferenceError (let)\nlet w = 1;\n```\n\n## Common Pitfalls\n- `var` in loops creates a single shared variable\n- `const` objects can still have properties modified\n- Accessing `let/const` before declaration throws `ReferenceError`\n\n## Best Practices\nUse `const` by default for immutability, `let` only when reassignment is necessary, and avoid `var` entirely in modern JavaScript to prevent scope-related bugs.","diagram":"graph TD\n    A[Variable Declaration] --> B[var]\n    A --> C[let]\n    A --> D[const]\n    B --> E[Function Scoped]\n    B --> F[Hoisted with undefined]\n    B --> G[Can Redeclare]\n    C --> H[Block Scoped]\n    C --> I[Temporal Dead Zone]\n    C --> J[Can Reassign]\n    D --> K[Block Scoped]\n    D --> L[Temporal Dead Zone]\n    D --> M[Cannot Reassign]\n    D --> N[Object Properties Mutable]","difficulty":"beginner","tags":["js","core"],"channel":"frontend","subChannel":"javascript","sourceUrl":null,"videos":null,"companies":null,"eli5":"Imagine you have three toy boxes for your toys! ðŸ“¦\n\n`var` is like a big toy box that anyone in the whole house can play with - even your brothers and sisters in other rooms!\n\n`let` is like a small toy box just for your bedroom - only you can play with these toys when you're in your room.\n\n`const` is like a toy that comes sealed in its package - you can play with it, but you can't trade it for a different toy!\n\nThe big toy box (`var`) can be moved anywhere in the house, but the bedroom boxes (`let` and `const`) stay in your room. And the sealed toy (`const`) can never be changed, while your other toys (`let`) can be swapped around anytime you want! ðŸŽ®","relevanceScore":null,"lastUpdated":"2025-12-23T06:37:19.169Z","createdAt":"2025-12-23 12:53:10"},{"id":"fr-162","question":"Explain how JavaScript's event loop handles microtasks vs macrotasks. What happens when a Promise resolves inside a setTimeout callback?","answer":"Microtasks (Promises) execute before macrotasks (setTimeout). Promise in setTimeout runs after that setTimeout completes, before next macrotask.","explanation":"## Event Loop: Microtasks vs Macrotasks\n\n### Task Queue Types\n\n**Macrotasks (Task Queue):**\n- `setTimeout`, `setInterval`\n- `setImmediate` (Node.js)\n- I/O operations\n- UI rendering\n\n**Microtasks (Job Queue):**\n- `Promise.then/catch/finally`\n- `queueMicrotask()`\n- `MutationObserver`\n- `process.nextTick` (Node.js - highest priority)\n\n### Execution Order\n\n1. Execute synchronous code\n2. Execute ALL microtasks in queue\n3. Execute ONE macrotask\n4. Execute ALL microtasks again\n5. Render (if needed)\n6. Repeat from step 3\n\n### Example Analysis\n\n```javascript\nconsole.log('1');\n\nsetTimeout(() => {\n  console.log('2');\n  Promise.resolve().then(() => console.log('3'));\n}, 0);\n\nPromise.resolve().then(() => {\n  console.log('4');\n  setTimeout(() => console.log('5'), 0);\n});\n\nconsole.log('6');\n```\n\n**Output:** 1, 6, 4, 2, 3, 5\n\n**Why:**\n- `1`, `6`: Synchronous code runs first\n- `4`: Microtask queue empties before any macrotask\n- `2`: First macrotask (setTimeout) executes\n- `3`: Microtasks from that macrotask run immediately\n- `5`: Next macrotask (setTimeout queued from Promise)\n\n### Key Insight\n\nWhen a Promise resolves inside setTimeout, it creates a microtask that executes **after** the current macrotask completes but **before** the next macrotask. This prevents macrotask starvation and ensures Promise handlers run promptly.","diagram":"graph TD\n    A[Call Stack] --> B{Stack Empty?}\n    B -->|Yes| C[Check Microtask Queue]\n    C -->|Has Microtasks| D[Execute ALL Microtasks]\n    D --> C\n    C -->|Empty| E[Check Macrotask Queue]\n    E -->|Has Macrotasks| F[Execute ONE Macrotask]\n    F --> B\n    E -->|Empty| G[Wait for Tasks]\n    G --> B\n    B -->|No| H[Execute Current Function]\n    H --> B\n    \n    style C fill:#90EE90\n    style D fill:#90EE90\n    style E fill:#FFB6C1\n    style F fill:#FFB6C1","difficulty":"advanced","tags":["js","core"],"channel":"frontend","subChannel":"javascript","sourceUrl":null,"videos":{"longVideo":"https://www.youtube.com/watch?v=8aGhZQkoFbQ"},"companies":["Airbnb","Google","Meta","Netflix","Stripe"],"eli5":"Imagine you're playing with toys! Microtasks are like tiny, important puzzle pieces you must finish right away. Macrotasks are like big playground activities that take longer. When a Promise (puzzle piece) resolves inside a setTimeout (playground activity), it's like finding a special treasure while playing on the slide. You finish your slide ride first (the setTimeout), then immediately work on your treasure puzzle (the Promise) before starting the next big playground game. The little puzzles always jump to the front of the line!","relevanceScore":null,"lastUpdated":"2025-12-21T13:06:52.203Z","createdAt":"2025-12-23 12:53:08"},{"id":"fr-173","question":"What is the output of this code and explain the event loop behavior: console.log('A'); setTimeout(() => console.log('B'), 0); Promise.resolve().then(() => console.log('C')); Promise.resolve().then(() => console.log('D')); console.log('E'); How do microtask and macrotask queues interact in JavaScript's event loop?","answer":"Output: A, E, C, D, B. The event loop processes all microtasks (Promise callbacks) before the next macrotask (setTimeout). Promise.resolve() creates immediately resolved promises that queue microtasks. Microtasks have higher priority than macrotasks, ensuring Promise chains execute before timers or I/O callbacks.","explanation":"## Interview Context\nThis tests understanding of JavaScript's event loop, crucial for frontend performance and async patterns.\n\n## Core Concepts\n- **Call Stack**: Executes synchronous code first (A, E)\n- **Microtask Queue**: Promise callbacks, processed immediately after stack clears\n- **Macrotask Queue**: setTimeout, I/O, processed after microtasks\n- **Promise.resolve()**: Creates immediately resolved promise, schedules microtask\n\n## Processing Order\n1. Synchronous: console.log('A'), console.log('E')\n2. Microtask queue drains: Promise callbacks (C, D)\n3. Macrotask queue: setTimeout callback (B)\n\n## Key Insight\nMicrotasks have higher priority than macrotasks. The event loop won't process any macrotasks until the microtask queue is completely empty.\n\n## Follow-up Questions\n- How would async/await affect this output?\n- What happens with nested Promise.resolve().then() chains?\n- How does requestAnimationFrame fit into the event loop?","diagram":"graph TD\n    A[Start] --> B[console.log'A']\n    B --> C[console.log'E']\n    C --> D[Microtask Queue Empty?]\n    D -->|Yes| E[Execute Promise.then C]\n    E --> F[Execute Promise.then D]\n    F --> G[Microtask Queue Empty?]\n    G -->|Yes| H[Execute setTimeout B]\n    H --> I[End]\n    D -->|No| J[Wait for Microtasks]\n    J --> D\n    G -->|No| K[Wait for Microtasks]\n    K --> G","difficulty":"advanced","tags":["js","core"],"channel":"frontend","subChannel":"javascript","sourceUrl":null,"videos":null,"companies":null,"eli5":"Imagine you're playing with toy blocks! First, you put block A on the floor (that's console.log 'A'). Then you tell your friend 'Hey, put block B on the floor in a second!' (that's setTimeout). Next, you have two special magic blocks C and D that appear right away (those are Promises). Finally, you put block E on the floor. The magic blocks C and D always appear before your friend remembers to put block B down. So you see: A, E, C, D, B. The magic blocks are faster than waiting for your friend!","relevanceScore":null,"lastUpdated":"2025-12-22T07:40:41.385Z","createdAt":"2025-12-23 12:53:08"},{"id":"q-240","question":"What is a closure in JavaScript and how does it enable data encapsulation?","answer":"A closure is when a function remembers and accesses variables from its outer lexical scope, even after the outer function has finished executing.","explanation":"## Concept Overview\nA closure is a fundamental JavaScript concept where an inner function maintains access to variables in its outer (lexical) scope, even when the outer function has completed execution. This creates a private scope for data encapsulation.\n\n## Implementation Details\n- Closures are created automatically when functions are defined inside other functions\n- The inner function retains a reference to the outer function's variables\n- This enables private variables and methods, similar to object-oriented encapsulation\n- Memory is managed automatically - closures persist as long as references exist\n\n## Code Example\n```javascript\nfunction createCounter() {\n  let count = 0; // Private variable\n  \n  return {\n    increment: function() {\n      count++; // Accesses outer scope variable\n      return count;\n    },\n    decrement: function() {\n      count--;\n      return count;\n    },\n    getCount: function() {\n      return count;\n    }\n  };\n}\n\nconst counter = createCounter();\nconsole.log(counter.increment()); // 1\nconsole.log(counter.increment()); // 2\nconsole.log(counter.getCount());  // 2\n```\n\n## Common Pitfalls\n- **Memory leaks**: Closures can prevent garbage collection if references persist unnecessarily\n- **Loop confusion**: Variables in closures capture by reference, not value (use `let` or IIFE)\n- **Performance impact**: Creating many closures can affect memory usage\n- **`this` binding**: Arrow functions don't have their own `this`, which affects closure behavior","diagram":"graph TD\n    A[Outer Function Called] --> B[Outer Variables Created]\n    B --> C[Inner Function Defined]\n    C --> D[Inner Function Returned]\n    D --> E[Outer Function Completes]\n    E --> F[Inner Function Still Has Access]\n    F --> G[Closure Maintains Reference]\n    G --> H[Private Data Encapsulation]","difficulty":"beginner","tags":["js","es6","closures","promises"],"channel":"frontend","subChannel":"javascript","sourceUrl":"https://dmitripavlutin.com/javascript-closures-interview-questions/","videos":{"shortVideo":"https://www.youtube.com/watch?v=vKJpN5FAeF4","longVideo":"https://www.youtube.com/watch?v=3a0I8ICR1Vg"},"companies":["Airbnb","Amazon","Apple","Google","Meta","Microsoft","Netflix","Uber"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T05:09:05.041Z","createdAt":"2025-12-23 12:53:08"},{"id":"q-351","question":"You're building a file upload component that processes multiple files in parallel. How would you implement a concurrent upload queue with a maximum of 3 simultaneous uploads using Promise.allSettled and closures?","answer":"Create a queue system that tracks active uploads, uses closures to manage state, and Promise.allSettled to handle partial failures gracefully.","explanation":"## Why This Is Asked\nTests understanding of async patterns, concurrency control, error handling, and closure-based state management - critical for production frontend systems.\n\n## Expected Answer\nStrong candidates will discuss: queue management with closures, Promise.allSettled vs Promise.all, handling partial failures, progress tracking, and cleanup mechanisms.\n\n## Code Example\n```javascript\nfunction createUploadQueue(maxConcurrent = 3) {\n  let activeUploads = 0;\n  const queue = [];\n  \n  return async function uploadFile(file) {\n    return new Promise((resolve, reject) => {\n      const processUpload = async () => {\n        activeUploads++;\n        try {\n          const result = await uploadToServer(file);\n          resolve(result);\n        } catch (error) {\n          reject(error);\n        } finally {\n          activeUploads--;\n          if (queue.length) queue.shift()();\n        }\n      };\n      \n      if (activeUploads < maxConcurrent) {\n        processUpload();\n      } else {\n        queue.push(processUpload);\n      }\n    });\n  };\n}\n\n// Usage\nconst uploadQueue = createUploadQueue(3);\nconst files = [file1, file2, file3, file4, file5];\nconst results = await Promise.allSettled(\n  files.map(file => uploadQueue(file))\n);\n```\n\n## Follow-up Questions\n- How would you add retry logic for failed uploads?\n- What changes needed for pause/resume functionality?\n- How would you handle upload progress reporting?","diagram":"flowchart TD\n  A[File Upload Request] --> B{Active Uploads < 3?}\n  B -->|Yes| C[Process Upload Immediately]\n  B -->|No| D[Add to Queue]\n  C --> E[Upload to Server]\n  D --> F[Wait for Slot]\n  F --> E\n  E --> G{Upload Success?}\n  G -->|Yes| H[Resolve Promise]\n  G -->|No| I[Reject Promise]\n  H --> J[Decrement Active Count]\n  I --> J\n  J --> K{Queue Has Items?}\n  K -->|Yes| L[Process Next in Queue]\n  K -->|No| M[Complete]\n  L --> E","difficulty":"intermediate","tags":["js","es6","closures","promises"],"channel":"frontend","subChannel":"javascript","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=k0m9ZrDjGmY","longVideo":"https://www.youtube.com/watch?v=fJkCv5Xxvnk"},"companies":["Amazon","Anthropic","Microsoft"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-23T12:59:08.932Z","createdAt":"2025-12-23 12:53:09"},{"id":"q-462","question":"Implement a rate-limited API wrapper that queues requests when the limit is reached, using closures to maintain state and promises to handle request ordering?","answer":"Create a closure with queue array and processing flag. Use Promise chain to maintain FIFO order. When limit hit, queue requests and process sequentially after delay. Leverage async/await with setTimeo","explanation":"## Solution Overview\nUse closure to encapsulate rate limiter state with request queue and timer.\n\n## Key Components\n- Queue array for pending requests\n- Processing flag to prevent race conditions\n- Promise chaining for FIFO ordering\n- Timer-based rate limit enforcement\n\n## Implementation\n```javascript\nconst createRateLimiter = (limit, interval) => {\n  const queue = [];\n  let processing = false;\n  let lastRequest = 0;\n  \n  return async (request) => {\n    return new Promise((resolve, reject) => {\n      queue.push({ request, resolve, reject });\n      processQueue();\n    });\n  };\n  \n  async function processQueue() {\n    if (processing || queue.length === 0) return;\n    processing = true;\n    \n    while (queue.length > 0) {\n      const now = Date.now();\n      if (now - lastRequest < interval) {\n        await new Promise(r => setTimeout(r, interval - (now - lastRequest)));\n      }\n      \n      const { request, resolve, reject } = queue.shift();\n      lastRequest = Date.now();\n      \n      try {\n        const result = await request();\n        resolve(result);\n      } catch (error) {\n        reject(error);\n      }\n    }\n    \n    processing = false;\n  }\n};\n```\n\n## Advanced Considerations\n- Memory management for long-running queues\n- Error propagation and retry logic\n- Dynamic limit adjustment based on server responses","diagram":"flowchart TD\n  A[Request Received] --> B{Queue Empty?}\n  B -->|Yes| C[Check Rate Limit]\n  B -->|No| D[Add to Queue]\n  C -->|Within Limit| E[Execute Request]\n  C -->|Exceeded| F[Wait for Interval]\n  F --> E\n  E --> G[Return Response]\n  D --> H[Process Queue FIFO]\n  H --> E","difficulty":"advanced","tags":["js","es6","closures","promises"],"channel":"frontend","subChannel":"javascript","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Lyft","Scale Ai"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-24T02:46:18.861Z","createdAt":"2025-12-24T02:46:18.861Z"},{"id":"fr-154","question":"What are the performance implications and layout shift consequences of loading large images without explicit dimensions, and how do modern CSS properties and loading strategies mitigate these issues?","answer":"Loading images without dimensions causes Cumulative Layout Shift (CLS) as browsers reflow content once image metadata loads. This impacts Core Web Vitals, degrades user experience, and can hurt SEO scores. Modern solutions include CSS aspect-ratio property, width/height attributes, lazy loading, and responsive image techniques to reserve space and optimize rendering pipeline performance.","explanation":"## Layout Shift Impact\n\nWithout explicit dimensions, browsers initially allocate zero space for images, causing content reflow when image dimensions are discovered. This creates CLS, affecting user experience and search rankings.\n\n## Performance Consequences\n\n- **LCP Degradation**: Largest Contentful Paint timing affected by layout reflows\n- **CLS Penalties**: Cumulative Layout Shift scores increase, impacting Core Web Vitals\n- **Rendering Pipeline**: Multiple reflow/repaint cycles waste CPU resources\n- **Network Inefficiency**: No pre-allocation hints for resource scheduling\n\n## Modern Solutions\n\n```html\n<!-- HTML attributes -->\n<img src=\"photo.jpg\" width=\"800\" height=\"600\" loading=\"lazy\">\n\n<!-- CSS aspect-ratio -->\n<img style=\"aspect-ratio: 4/3; width: 100%;\" src=\"photo.jpg\">\n\n<!-- Responsive images -->\n<img srcset=\"small.jpg 800w, large.jpg 1600w\" \n     sizes=\"(max-width: 800px) 100vw, 50vw\"\n     width=\"1600\" height=\"1200\">\n```\n\n## CSS Aspect-Ratio Property\n\nThe `aspect-ratio` property reserves space before image loading, preventing layout shifts:\n\n```css\n.responsive-image {\n  width: 100%;\n  aspect-ratio: 16/9;\n  object-fit: cover;\n}\n```\n\n## Loading Strategies\n\n- **Lazy Loading**: `loading=\"lazy\"` defers offscreen images\n- **Progressive Enhancement**: Low-quality image placeholders (LQIP)\n- **Priority Hints**: `fetchpriority=\"high\"` for above-fold images\n- **Preload**: `<link rel=\"preload\" as=\"image\">` for critical images\n\n## Browser Optimization\n\nModern browsers use image metadata to calculate dimensions early, but explicit attributes provide immediate layout information, enabling efficient rendering pipeline optimization and better resource scheduling.","diagram":"graph TD\n    A[Browser Starts Parsing HTML] --> B[Encounters img Tag]\n    B --> C{Has width/height?}\n    C -->|No| D[Reserves 0px Space]\n    C -->|Yes| E[Reserves Correct Space]\n    D --> F[Renders Page]\n    E --> G[Renders Page]\n    F --> H[Image Downloads]\n    H --> I[Browser Calculates Size]\n    I --> J[Content Shifts Down]\n    J --> K[Poor CLS Score]\n    G --> L[Image Downloads]\n    L --> M[Fills Reserved Space]\n    M --> N[No Layout Shift]\n    N --> O[Good CLS Score]","difficulty":"beginner","tags":["perf","optimization"],"channel":"frontend","subChannel":"performance","sourceUrl":null,"videos":null,"companies":null,"eli5":"Imagine you're building a tower with toy blocks. You place all your blocks where you think they should go, but then you realize one block is actually much bigger than you expected! When you put it in, all the other blocks have to slide around to make room. That's what happens when a big picture shows up on a website without telling the computer how big it will be first. Everything else jumps around to make space for the picture. It's like when you're setting the dinner table and someone puts a huge pizza in the middle - all the plates and cups have to wiggle around to fit!","relevanceScore":73,"lastUpdated":"2025-12-24T06:27:45.657Z","createdAt":"2025-12-23 12:53:10"},{"id":"fr-163","question":"You have a React app rendering a list of 10,000 items. Each item has a complex component with multiple child components. The list scrolls slowly and feels janky. Describe three different optimization strategies you would apply, explaining when to use each approach and their trade-offs.","answer":"Use virtualization (react-window), memoization (React.memo/useMemo), and code splitting. Each targets different bottlenecks.","explanation":"## Three Core Optimization Strategies\n\n### 1. Virtualization (react-window/react-virtual)\n\n**When to use:** Large lists where only a few items are visible at once\n\n**How it works:**\n- Only renders items currently in viewport + small buffer\n- Dynamically mounts/unmounts components as user scrolls\n- Reduces DOM nodes from 10,000 to ~20-30\n\n```javascript\nimport { FixedSizeList } from 'react-window';\n\nconst VirtualList = () => (\n  <FixedSizeList\n    height={600}\n    itemCount={10000}\n    itemSize={50}\n    width=\"100%\"\n  >\n    {({ index, style }) => (\n      <div style={style}>Item {index}</div>\n    )}\n  </FixedSizeList>\n);\n```\n\n**Trade-offs:**\n- âœ… Massive performance gain for long lists\n- âœ… Constant memory usage regardless of list size\n- âŒ Requires fixed/estimated item heights\n- âŒ Breaks native browser features (find-in-page, accessibility)\n\n### 2. Memoization (React.memo, useMemo, useCallback)\n\n**When to use:** Components re-rendering unnecessarily with same props\n\n**How it works:**\n- `React.memo`: Prevents re-render if props haven't changed\n- `useMemo`: Caches expensive computations\n- `useCallback`: Stabilizes function references\n\n```javascript\nconst ListItem = React.memo(({ item, onDelete }) => {\n  const formattedData = useMemo(\n    () => expensiveFormat(item.data),\n    [item.data]\n  );\n  \n  return <div onClick={onDelete}>{formattedData}</div>;\n});\n\nconst List = () => {\n  const handleDelete = useCallback((id) => {\n    deleteItem(id);\n  }, []);\n  \n  return items.map(item => (\n    <ListItem key={item.id} item={item} onDelete={handleDelete} />\n  ));\n};\n```\n\n**Trade-offs:**\n- âœ… Prevents wasted renders\n- âœ… Easy to implement incrementally\n- âŒ Adds memory overhead for memoization\n- âŒ Shallow comparison can miss deep object changes\n- âŒ Overuse can hurt performance (comparison cost)\n\n### 3. Code Splitting & Lazy Loading\n\n**When to use:** Heavy components not immediately needed\n\n**How it works:**\n- Split bundle into chunks\n- Load components on-demand\n- Reduce initial JavaScript payload\n\n```javascript\nconst HeavyChart = lazy(() => import('./HeavyChart'));\n\nconst ListItem = ({ item }) => (\n  <div>\n    <h3>{item.title}</h3>\n    <Suspense fallback={<Spinner />}>\n      {item.showChart && <HeavyChart data={item.data} />}\n    </Suspense>\n  </div>\n);\n```\n\n**Trade-offs:**\n- âœ… Faster initial load\n- âœ… Reduces main bundle size\n- âŒ Network delay when loading chunks\n- âŒ Requires loading states\n- âŒ Can cause layout shifts\n\n## Decision Matrix\n\n| Scenario | Best Strategy |\n|----------|---------------|\n| 10k+ simple items | Virtualization |\n| Complex items, frequent parent updates | Memoization |\n| Heavy dependencies per item | Code splitting |\n| All of the above | Combine all three |\n\n## Measuring Impact\n\nUse React DevTools Profiler to identify:\n- **Render duration**: How long each component takes\n- **Render frequency**: How often components re-render\n- **Wasted renders**: Components rendering with same props","diagram":"graph TD\n    A[10k Items List Problem] --> B{Identify Bottleneck}\n    B --> C[Too Many DOM Nodes]\n    B --> D[Unnecessary Re-renders]\n    B --> E[Large Bundle Size]\n    \n    C --> F[Virtualization]\n    F --> F1[Render only visible items]\n    F1 --> F2[~30 DOM nodes vs 10k]\n    \n    D --> G[Memoization]\n    G --> G1[React.memo on ListItem]\n    G1 --> G2[useMemo for computations]\n    G2 --> G3[useCallback for handlers]\n    \n    E --> H[Code Splitting]\n    H --> H1[Lazy load heavy components]\n    H1 --> H2[Reduce initial bundle]\n    \n    F2 --> I[Optimized App]\n    G3 --> I\n    H2 --> I\n    \n    style C fill:#ff6b6b\n    style D fill:#ffd93d\n    style E fill:#6bcf7f\n    style I fill:#4ecdc4","difficulty":"advanced","tags":["perf","optimization"],"channel":"frontend","subChannel":"performance","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=b0IZo2Aho9Y","longVideo":"https://www.youtube.com/watch?v=JU6sl_yyZqs"},"companies":["Airbnb","Google","Meta","Stripe","Uber"],"eli5":"Imagine you have 10,000 toy cars to show friends, but you can only see 10 at once! Instead of laying out all cars (virtualization), you only display the ones you can see and swap them as you scroll. For your favorite cars (memoization), you wrap them in special plastic so they don't get dusty when you move them around. And for the toy factory (code splitting), you keep different car parts in separate boxes - you only open the wheel box when someone wants to see wheels, not all parts at once!","relevanceScore":null,"lastUpdated":"2025-12-21T13:08:26.427Z","createdAt":"2025-12-23 12:53:08"},{"id":"fr-172","question":"How would you optimize rendering performance for a React component displaying a large list (10,000+ items) with frequent real-time updates?","answer":"Implement react-window for virtualization, useMemo for expensive calculations, useCallback for stable function references, and useTransition for non-urgent updates. Apply key prop strategies, batch state updates, and leverage React.memo with custom comparison functions to minimize unnecessary re-renders.","explanation":"## Interview Context\nThis question tests React performance optimization knowledge for real-world scenarios with large datasets and frequent updates, essential for enterprise applications.\n\n## Key Concepts\n- **Virtualization**: Only render visible items using react-window or react-virtualized\n- **Memoization**: Use useMemo for expensive calculations and useCallback for stable references\n- **State Management**: Optimize state updates with useReducer and batching\n- **Key Strategies**: Use stable, unique keys for efficient reconciliation\n- **Concurrent Features**: leverage useTransition and useDeferredValue for smooth UX\n\n## Implementation Strategy\n```javascript\nconst OptimizedList = ({ items, onSelect }) => {\n  const memoizedItems = useMemo(() => \n    items.map(item => ({...item, processed: true})), [items]\n  );\n  \n  const handleSelect = useCallback((id) => {\n    startTransition(() => onSelect(id));\n  }, [onSelect]);\n  \n  return (\n    <FixedSizeList\n      height={600}\n      itemCount={memoizedItems.length}\n      itemSize={50}\n      itemData={memoizedItems}\n    >\n      {MemoizedRow}\n    </FixedSizeList>\n  );\n};\n\nconst MemoizedRow = React.memo(({ index, style, data }) => (\n  <div style={style} onClick={() => handleSelect(data[index].id)}>\n    {data[index].name}\n  </div>\n));\n```\n\n## Follow-up Questions\n- How would you handle sorting and filtering while maintaining performance?\n- What trade-offs would you consider between client-side vs server-side virtualization?\n- How would you optimize for mobile devices with limited memory?","diagram":"graph TD\n    A[Large List Data] --> B[Virtualization Layer]\n    B --> C[Visible Items Only 20-50]\n    C --> D[Memoized Components]\n    D --> E[Optimized DOM]\n    \n    F[User Input] --> G[Debounce 300ms]\n    G --> H[Batched Updates]\n    H --> I[Minimal Re-renders]\n    \n    J[React.memo] --> K[Props Comparison]\n    K --> L[Skip Unnecessary Renders]\n    \n    M[Stable Keys] --> N[Efficient Reconciliation]\n    N --> O[Fast DOM Updates]","difficulty":"intermediate","tags":["perf","optimization"],"channel":"frontend","subChannel":"performance","sourceUrl":null,"videos":null,"companies":null,"eli5":"Imagine you have 10,000 toy cars but only a small box to show them in! Instead of putting all cars in the box at once, you only keep the cars you can see right now. When you want to see different cars, you swap out the ones you can't see for new ones. Also, you put little name tags on each car so you don't have to check them over and over again. And when your friend keeps asking to see different cars really fast, you wait a second before actually changing the cars - like taking a deep breath before doing something quickly!","relevanceScore":null,"lastUpdated":"2025-12-22T09:59:23.607Z","createdAt":"2025-12-23 12:53:09"},{"id":"q-188","question":"How would you implement a performance budget system that automatically detects bundle regressions and enforces lazy-loading boundaries in a large-scale React application?","answer":"Use webpack-bundle-analyzer with performance budgets, implement dynamic imports with React.lazy, and set up CI checks to enforce bundle size limits.","explanation":"## Performance Budget System\n\n### Concept Overview\nA performance budget system enforces quantitative limits on bundle sizes, loading times, and resource utilization to maintain optimal user experience.\n\n### Implementation Details\n\n**Bundle Analysis:**\n- Configure webpack-bundle-analyzer for visual bundle inspection\n- Set performance budgets in webpack config (maxAssetSize, maxEntrypointSize)\n- Implement bundle-size diff in CI pipeline\n\n**Lazy Loading Boundaries:**\n- Use React.lazy() with Suspense for component-level code splitting\n- Implement route-based splitting with dynamic imports\n- Set up intersection observer for below-fold content\n\n**Monitoring & Enforcement:**\n- Integrate Lighthouse CI for automated performance scoring\n- Create custom webpack plugins for boundary enforcement\n- Set up alerts for budget violations\n\n### Code Example\n```javascript\n// webpack.config.js\nperformance: {\n  budgets: [{\n    type: 'initial',\n    maxEntrypointSize: 244000,\n    maxAssetSize: 244000\n  }]\n}\n\n// React.lazy implementation\nconst HeavyComponent = React.lazy(() => \n  import('./HeavyComponent').then(module => ({\n    default: module.default\n  }))\n);\n```\n\n### Common Pitfalls\n- Over-splitting causing excessive network requests\n- Missing proper loading states for lazy components\n- Ignoring third-party bundle impact on budgets\n- Not accounting for browser caching strategies","diagram":"flowchart LR\n    A[Code Commit] --> B[Webpack Build]\n    B --> C[Bundle Analysis]\n    C --> D{Budget Check}\n    D -->|Pass| E[Deploy]\n    D -->|Fail| F[Alert Team]\n    C --> G[Lazy Loading Boundaries]\n    G --> H[Dynamic Imports]\n    H --> I[Route Splitting]\n    I --> J[Component Splitting]\n    J --> K[Intersection Observer]\n    K --> L[Below-fold Content]","difficulty":"advanced","tags":["lighthouse","bundle","lazy-loading"],"channel":"frontend","subChannel":"performance","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=0fONene3OIA","longVideo":"https://www.youtube.com/watch?v=JU6sl_yyZqs"},"companies":["Airbnb","Atlassian","LinkedIn","Netflix","Uber"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T05:09:25.836Z","createdAt":"2025-12-23 12:53:08"},{"id":"q-301","question":"How would you optimize a React app's bundle size to achieve Lighthouse scores above 90, and what specific tools and metrics would you use to measure success?","answer":"Implement code splitting with React.lazy() and Suspense, configure webpack bundle analyzer for visualization, use dynamic imports for vendor chunks, enable tree shaking with ES6 modules, set performance budgets <170KB gzipped, and configure chunk splitting patterns for optimal caching.","explanation":"## Interview Context\nThis evaluates frontend performance optimization skills and tooling knowledge for senior-level positions requiring production-ready applications.\n\n## Key Concepts\n- Bundle analysis using webpack-bundle-analyzer or source-map-explorer\n- Performance budgets and Lighthouse Core Web Vitals\n- Tree shaking with ES6 modules and sideEffects configuration\n- Code splitting strategies (route-based, component-based, vendor chunks)\n\n## Implementation Approach\n```javascript\n// Dynamic import with React.lazy\nconst Dashboard = React.lazy(() => import('./Dashboard'));\n\n// Webpack chunk splitting configuration\noptimization: {\n  splitChunks: {\n    chunks: 'all',\n    cacheGroups: {\n      vendor: {\n        test: /[\\\\/]node_modules[\\\\/]/,\n        name: 'vendors',\n        chunks: 'all'\n      }\n    }\n  }\n}\n```\n\n## Follow-up Questions\n- How would you implement component-level code splitting?\n- What metrics would you track in a performance budget?\n- How do you handle third-party library optimization?","diagram":"flowchart TD\n  A[Initial Bundle Analysis] --> B[Webpack Bundle Analyzer]\n  B --> C{Bundle > 170KB gzipped?}\n  C -->|Yes| D[Implement Code Splitting]\n  C -->|No| E[Tree Shaking Optimization]\n  D --> F[React.lazy + Suspense Components]\n  D --> G[Dynamic Import Vendor Chunks]\n  E --> H[ES6 Modules Tree Shaking]\n  F --> I[Configure Chunk Splitting Patterns]\n  G --> I\n  H --> I\n  I --> J[Set Performance Budgets]\n  J --> K[Run Lighthouse Audit]\n  K --> L{Scores > 90?}\n  L -->|Yes| M[Deploy Optimized Bundle]\n  L -->|No| N[Iterate on Optimizations]\n  N --> A","difficulty":"beginner","tags":["lighthouse","bundle","lazy-loading"],"channel":"frontend","subChannel":"performance","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=ROKRTZ_xCgo","longVideo":"https://www.youtube.com/watch?v=-4fyyyQjsz8"},"companies":null,"eli5":"Imagine your app is a big toy box. Right now, you have to carry the whole heavy box everywhere you go! Instead, let's make small toy bags - one for cars, one for dolls, one for blocks. You only carry the bag you want to play with right now. We use special tools like a magic scale that tells us exactly how heavy each bag is. We want each bag to be as light as a small apple, not as heavy as a watermelon. We can also remove any broken toys or duplicates to make the bags lighter. When we make the bags lighter and only grab what we need, our app runs super fast and everyone can play quickly - just like how you can run faster when you're not carrying a huge backpack!","relevanceScore":null,"lastUpdated":"2025-12-22T13:23:10.842Z","createdAt":"2025-12-23 12:53:09"},{"id":"q-329","question":"You're tasked with improving a React app's Lighthouse performance score from 65 to 90+. The bundle size is 2.1MB and Time to Interactive is 4.2s. What specific steps would you take to optimize the bundle and implement lazy loading?","answer":"Implement code splitting with React.lazy(), analyze bundle with webpack-bundle-analyzer, remove unused dependencies, add dynamic imports for heavy components.","explanation":"## Why This Is Asked\nTests practical performance optimization skills and understanding of modern frontend tooling. Scale AI needs engineers who can deliver fast, scalable user experiences.\n\n## Expected Answer\nStrong candidates will mention: 1) Bundle analysis to identify largest chunks, 2) Code splitting strategies (route-based vs component-based), 3) Tree shaking configuration, 4) Dynamic imports for non-critical features, 5) Image optimization and lazy loading, 6) Service worker caching strategy.\n\n## Code Example\n```javascript\n// Route-based code splitting\nconst Dashboard = React.lazy(() => import('./Dashboard'));\nconst Analytics = React.lazy(() => import('./Analytics'));\n\n// Component-based lazy loading\nconst HeavyChart = React.lazy(() => import('./HeavyChart'));\n\n// Dynamic import for user interaction\nconst loadAdminPanel = () => import('./AdminPanel');\n```\n\n## Follow-up Questions\n- How would you measure the impact of each optimization?\n- What trade-offs exist between bundle size and runtime performance?\n- How would you handle lazy loading for SEO-critical content?","diagram":"flowchart TD\n  A[Analyze Bundle] --> B[Identify Large Chunks]\n  B --> C[Implement Code Splitting]\n  C --> D[Add Lazy Loading]\n  D --> E[Optimize Images]\n  E --> F[Measure Results]","difficulty":"intermediate","tags":["lighthouse","bundle","lazy-loading"],"channel":"frontend","subChannel":"performance","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=ROKRTZ_xCgo","longVideo":"https://www.youtube.com/watch?v=JU6sl_yyZqs"},"companies":["Amazon","Google","Mckinsey","Meta","Microsoft","Netflix","Scale Ai","Stripe"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T13:37:46.868Z","createdAt":"2025-12-23 12:53:09"},{"id":"q-378","question":"You're building a real-time trading dashboard at DE Shaw that needs to display 1000+ rapidly updating price cards. How would you optimize CSS layout and animations to maintain 60fps while cards are being added/removed/updated every 100ms?","answer":"Use CSS containment, will-change, transform3d for GPU acceleration, and virtualized rendering with requestAnimationFrame batching.","explanation":"## Why This Is Asked\nDE Shaw needs high-performance trading interfaces. This tests understanding of browser rendering pipeline, CSS optimization, and performance profiling under extreme conditions.\n\n## Expected Answer\nStrong candidates discuss: CSS containment (layout/paint isolation), transform3d for compositing, will-change sparingly, virtualization for large lists, requestAnimationFrame batching, avoiding layout thrashing, and measuring performance with Chrome DevTools.\n\n## Code Example\n```css\n.price-card {\n  contain: layout style paint;\n  will-change: transform;\n  transform: translate3d(0, 0, 0);\n}\n.price-update {\n  transition: color 0.1s, background 0.1s;\n}\n```\n\n## Follow-up Questions\n- How would you handle browser differences in rendering performance?\n- What metrics would you monitor to ensure 60fps?\n- How would you debug layout thrashing in this scenario?","diagram":"flowchart TD\n  A[Price Data Update] --> B[Batch with requestAnimationFrame]\n  B --> C[Virtual List Rendering]\n  C --> D[CSS Containment Isolation]\n  D --> E[GPU Acceleration with transform3d]\n  E --> F[60fps Frame Display]\n  F --> G{Performance Check}\n  G -->|Below 60fps| H[Optimize Containment]\n  G -->|Above 60fps| I[Continue Rendering]\n  H --> E","difficulty":"advanced","tags":["css","flexbox","grid","animations"],"channel":"frontend","subChannel":"performance","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DE Shaw","Discord","Instacart"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T12:47:09.434Z","createdAt":"2025-12-23 12:53:09"},{"id":"q-390","question":"You're working on a React app that loads slowly. Your Lighthouse performance score is 45. What specific steps would you take to improve it, and how would you implement lazy loading for a heavy component?","answer":"Analyze bundle with webpack-bundle-analyzer, implement code splitting with React.lazy(), add loading states, and optimize images with WebP format.","explanation":"## Why This Is Asked\nNvidia wants candidates who can diagnose performance issues systematically and implement practical optimizations that impact user experience.\n\n## Expected Answer\nA strong candidate would mention: 1) Running Lighthouse to identify specific bottlenecks, 2) Using webpack-bundle-analyzer to find large chunks, 3) Implementing React.lazy() for route-level splitting, 4) Adding Suspense with fallback UI, 5) Optimizing images and removing unused dependencies.\n\n## Code Example\n```javascript\n// Before: Heavy component loads immediately\nimport HeavyChart from './HeavyChart';\n\n// After: Lazy loaded with loading state\nconst HeavyChart = React.lazy(() => import('./HeavyChart'));\n\nfunction App() {\n  return (\n    <Suspense fallback={<div>Loading chart...</div>}>\n      <HeavyChart />\n    </Suspense>\n  );\n}\n```\n\n## Follow-up Questions\n- How would you measure the impact of your optimizations?\n- What's the difference between code splitting and tree shaking?\n- How would you handle lazy loading for multiple components on the same page?","diagram":"flowchart TD\n    A[Initial Load Lighthouse 45] --> B[Run Bundle Analysis]\n    B --> C[Identify Large Chunks]\n    C --> D[Implement React.lazy Code Splitting]\n    D --> E[Add Suspense Fallback UI]\n    E --> F[Optimize Images to WebP]\n    F --> G[Remove Unused Dependencies]\n    G --> H[Re-run Lighthouse Score 85+]","difficulty":"beginner","tags":["lighthouse","bundle","lazy-loading"],"channel":"frontend","subChannel":"performance","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Crowdstrike","Deepmind","NVIDIA"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T12:48:47.855Z","createdAt":"2025-12-23 12:53:09"},{"id":"q-395","question":"You're building a complex dashboard with a responsive grid layout that must support dynamic column insertion, reordering, and animated transitions. How would you implement this using CSS Grid and JavaScript while maintaining 60fps performance during large dataset updates (10,000+ items)?","answer":"Use CSS Grid with virtual scrolling, CSS transforms for animations, and requestAnimationFrame for batched DOM updates to maintain 60fps.","explanation":"## Why This Is Asked\nTests advanced CSS Grid mastery, performance optimization skills, and ability to handle large-scale UI challenges - critical for Google's complex web applications.\n\n## Expected Answer\nStrong candidates discuss CSS Grid auto-fit/minmax, virtual scrolling implementation, CSS transform-based animations for GPU acceleration, and batched DOM updates using requestAnimationFrame or DocumentFragment.\n\n## Code Example\n```javascript\n// Virtualized grid with performant updates\nclass VirtualizedGrid {\n  constructor(container, data) {\n    this.container = container;\n    this.data = data;\n    this.visibleStart = 0;\n    this.visibleEnd = 50;\n    this.setupGrid();\n  }\n  \n  setupGrid() {\n    this.container.style.display = 'grid';\n    this.container.style.gridTemplateColumns = 'repeat(auto-fit, minmax(250px, 1fr))';\n    this.container.style.gap = '16px';\n  }\n  \n  updateData(newData) {\n    requestAnimationFrame(() => {\n      const fragment = document.createDocumentFragment();\n      newData.slice(this.visibleStart, this.visibleEnd).forEach(item => {\n        const el = this.createItem(item);\n        el.style.transform = 'translateY(0)';\n        el.style.transition = 'transform 0.3s ease';\n        fragment.appendChild(el);\n      });\n      this.container.innerHTML = '';\n      this.container.appendChild(fragment);\n    });\n  }\n}\n```\n\n## Follow-up Questions\n- How would you handle column reordering with animations?\n- What strategies would you use for memory management with 10,000+ items?\n- How would you implement accessibility for this dynamic grid?","diagram":"flowchart TD\n  A[CSS Grid Container] --> B[Virtual Viewport Calculation]\n  B --> C[Visible Items Range]\n  C --> D[RequestAnimationFrame Batch]\n  D --> E[DocumentFragment Creation]\n  E --> F[GPU-Accelerated Transforms]\n  F --> G[60fps Render Loop]\n  G --> H{Scroll Event}\n  H -->|Yes| B\n  H -->|No| I[Idle State]\n  I --> H","difficulty":"advanced","tags":["css","flexbox","grid","animations"],"channel":"frontend","subChannel":"performance","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Meta","Microsoft","Netflix","Salesforce","Stripe"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T12:49:43.625Z","createdAt":"2025-12-23 12:53:09"},{"id":"fe-1","question":"How does React's Virtual DOM diffing algorithm work during reconciliation, and what role do keys play in optimizing list updates?","answer":"React comparesæ–°æ—§VDOM trees using a heuristic O(n) algorithm, calculating minimal DOM patches. Keys enable stable element identity for efficient list updates.","explanation":"## Concept Overview\nVirtual DOM is a JavaScript representation of the real DOM that enables efficient updates through diffing and reconciliation. React creates a new VDOM tree on each render, compares it with the previous tree, and calculates the minimal changes needed.\n\n## Implementation\n```jsx\n// Without keys - inefficient re-renders\nfunction BadList({ items }) {\n  return items.map(item => <li>{item.name}</li>);\n}\n\n// With keys - optimized updates\nfunction GoodList({ items }) {\n  return items.map(item => <li key={item.id}>{item.name}</li>);\n}\n```\n\n**Diffing Algorithm Rules:**\n- Different element types â†’ replace entire subtree\n- Same element type â†’ update attributes only\n- Lists â†’ use keys to match elements\n\n## Trade-offs\n**Pros:**\n- Batched DOM updates improve performance\n- Declarative programming model\n- Cross-browser compatibility\n\n**Cons:**\n- Memory overhead for VDOM trees\n- Initial render slower than direct DOM manipulation\n- Not optimal for frequent small updates\n\n## Common Pitfalls\n- Using array indices as keys for mutable lists\n- Missing keys in dynamic lists causing unnecessary re-renders\n- Unstable keys causing component state loss\n- Over-relying on VDOM for performance-critical animations","diagram":"graph TD\n    A[State Change] --> B[Create New VDOM]\n    B --> C[Diff Algorithm]\n    C --> D{Element Type Same?}\n    D -->|No| E[Replace Entire Subtree]\n    D -->|Yes| F{Has Children?}\n    F -->|No| G[Update Attributes]\n    F -->|Yes| H{List with Keys?}\n    H -->|No| I[Reorder/Replace Children]\n    H -->|Yes| J[Match by Key Identity]\n    J --> K[Update Changed Elements]\n    K --> L[Batch DOM Updates]\n    E --> L\n    G --> L\n    I --> L","difficulty":"intermediate","tags":["react","perf","internals"],"channel":"frontend","subChannel":"react","sourceUrl":null,"videos":{"shortVideo":"https://youtube.com/watch?v=bRXXCGX_J2w","longVideo":"https://youtube.com/watch?v=UKn4aVlnB9A"},"companies":["Airbnb","Google","Meta","Microsoft","Netflix"],"eli5":"Imagine you have two boxes of LEGO blocks and want to make them match! React is like a smart kid who compares the boxes quickly. Instead of taking apart everything and rebuilding, React just looks for what's different - like finding which blocks moved or changed colors. The 'keys' are like name tags on your LEGO pieces. When you have a row of toy soldiers, each one has a name tag so React knows exactly which soldier moved where, instead of getting confused and rebuilding the whole line. This makes fixing changes super fast - just swapping the few pieces that actually changed!","relevanceScore":null,"lastUpdated":"2025-12-24T12:39:03.902Z","createdAt":"2025-12-23 12:53:08"},{"id":"fr-161","question":"How would you implement a React hook that tracks component render count and warns when it exceeds a threshold, while avoiding infinite render loops?","answer":"Use useRef to persist count across renders and useEffect with no deps to increment. Check threshold and warn without triggering re-render.","explanation":"## Implementation Strategy\n\n```javascript\nfunction useRenderCount(threshold = 50) {\n  const renderCount = useRef(0);\n  const hasWarned = useRef(false);\n  \n  renderCount.current += 1;\n  \n  if (renderCount.current > threshold && !hasWarned.current) {\n    console.warn(`Component rendered ${renderCount.current} times`);\n    hasWarned.current = true;\n  }\n  \n  return renderCount.current;\n}\n```\n\n## Key Concepts\n\n**Why useRef instead of useState?**\n- `useRef` doesn't trigger re-renders when updated\n- `useState` would cause infinite loop since updating state triggers render\n- Perfect for tracking values across renders without side effects\n\n**Avoiding Infinite Loops**\n- Never call `setState` directly in render body\n- Use `useRef` for mutable values that don't affect UI\n- `hasWarned` ref prevents repeated console warnings\n\n**When to Use**\n- Performance debugging in development\n- Detecting unnecessary re-renders\n- Monitoring component optimization effectiveness\n\n**Advanced Considerations**\n- Reset count on unmount with cleanup function\n- Add dev-only checks with `process.env.NODE_ENV`\n- Track render reasons with additional metadata","diagram":"graph TD\n    A[Component Renders] --> B[useRenderCount Hook Called]\n    B --> C[Increment renderCount.current]\n    C --> D{Count > Threshold?}\n    D -->|No| E[Return Count]\n    D -->|Yes| F{Already Warned?}\n    F -->|No| G[Log Warning]\n    F -->|Yes| E\n    G --> H[Set hasWarned = true]\n    H --> E\n    E --> I[Component Continues Rendering]\n    I -.->|Next Render| A\n    \n    style B fill:#61dafb\n    style C fill:#ffd700\n    style G fill:#ff6b6b","difficulty":"advanced","tags":["react","perf"],"channel":"frontend","subChannel":"react","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=ROKRTZ_xCgo","longVideo":"https://www.youtube.com/watch?v=00RoZflFE34"},"companies":["Airbnb","Microsoft","Netflix","Stripe","Uber"],"eli5":"Imagine you're building with LEGO blocks and want to count how many times you add a new block. You have a special sticker paper (useRef) that remembers your count even when you start over. Each time you build, you secretly add a tick mark on your paper (useEffect). When you reach 5 ticks, your mom warns you: 'That's too many blocks!' But the warning doesn't make you start over again - it just helps you notice you're building too much. This way, you can count your building without getting stuck in an endless loop of building!","relevanceScore":null,"lastUpdated":"2025-12-21T13:06:44.446Z","createdAt":"2025-12-23 12:53:08"},{"id":"q-215","question":"How would you implement a custom useDebounce hook that works with React's concurrent features and prevents stale closures?","answer":"Use useRef for latest value, useEffect with cleanup, and useCallback to maintain stable reference while handling concurrent renders.","explanation":"## Concept Overview\nA custom useDebounce hook delays function execution until after a specified wait time, crucial for search inputs and API calls.\n\n## Implementation Details\n- Use useRef to store the latest callback value, preventing stale closures\n- Implement cleanup in useEffect to cancel pending debounced calls\n- Return useCallback with stable dependencies for concurrent rendering\n- Handle component unmounting to prevent memory leaks\n\n## Code Example\n```javascript\nimport { useCallback, useRef, useEffect } from 'react';\n\nexport function useDebounce(callback, delay) {\n  const callbackRef = useRef(callback);\n  const timeoutRef = useRef(null);\n\n  useEffect(() => {\n    callbackRef.current = callback;\n  }, [callback]);\n\n  return useCallback((...args) => {\n    if (timeoutRef.current) {\n      clearTimeout(timeoutRef.current);\n    }\n    \n    timeoutRef.current = setTimeout(() => {\n      callbackRef.current(...args);\n    }, delay);\n  }, [delay]);\n}\n```\n\n## Common Pitfalls\n- Forgetting to update ref with latest callback causes stale closures\n- Not clearing timeout leads to multiple executions\n- Missing dependency array in useCallback causes unnecessary re-renders\n- Not handling component unmount can cause memory leaks","diagram":"flowchart LR\n    A[User Input] --> B[useDebounce Hook]\n    B --> C{Timeout Exists?}\n    C -->|Yes| D[Clear Previous Timeout]\n    C -->|No| E[Set New Timeout]\n    D --> E\n    E --> F[Wait Delay Period]\n    F --> G[Execute Callback]\n    G --> H[Update State/API Call]","difficulty":"intermediate","tags":["react","hooks","context","redux"],"channel":"frontend","subChannel":"react","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=MHm-2YmWEek","longVideo":"https://www.youtube.com/watch?v=xfKYYRE6-TQ"},"companies":["Amazon","Google","Meta","Microsoft","Uber"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-21T08:54:20.117Z","createdAt":"2025-12-23 12:53:08"},{"id":"q-239","question":"How would you implement a React useMemo hook to optimize a recursive Fibonacci function with memoization, and what are the key trade-offs between top-down memoization vs bottom-up tabulation in this context?","answer":"Use useMemo to cache expensive Fibonacci calculations, memoizing results to prevent O(2^n) recursion. Trade-offs: memoization uses recursion + cache (O(n) space), tabulation uses iteration (O(1) space","explanation":"## Concept Overview\nDynamic programming optimizes recursive problems by caching subproblem results. In React, useMemo prevents expensive recalculations during re-renders.\n\n## Implementation Details\n### Top-Down Memoization (Recursive)\n```javascript\nconst fibonacci = useMemo(() => {\n  const memo = {};\n  const fib = (n) => {\n    if (n in memo) return memo[n];\n    if (n <= 1) return n;\n    memo[n] = fib(n - 1) + fib(n - 2);\n    return memo[n];\n  };\n  return fib;\n}, []);\n```\n\n### Bottom-Up Tabulation (Iterative)\n```javascript\nconst fibonacci = useMemo(() => {\n  return (n) => {\n    if (n <= 1) return n;\n    let prev = 0, curr = 1;\n    for (let i = 2; i <= n; i++) {\n      [prev, curr] = [curr, prev + curr];\n    }\n    return curr;\n  };\n}, []);\n```\n\n## Common Pitfalls\n- **Dependency array**: Empty array [] ensures function isn't recreated\n- **Memory leaks**: Large memo objects can cause memory issues\n- **Over-optimization**: useMemo overhead may exceed benefits for simple calculations\n- **Referential equality**: useMemo preserves function reference for child components","diagram":"flowchart LR\n    A[Component Render] --> B{useMemo Cache Hit?}\n    B -->|Yes| C[Return Cached Result]\n    B -->|No| D[Calculate Fibonacci]\n    D --> E{Memoization Strategy}\n    E -->|Top-Down| F[Recursive + Cache]\n    E -->|Bottom-Up| G[Iterative + Variables]\n    F --> H[Store in Cache]\n    G --> I[Return Result]\n    H --> I\n    C --> J[Prevent Re-render]\n    I --> J","difficulty":"intermediate","tags":["dp","memoization","tabulation"],"channel":"frontend","subChannel":"react","sourceUrl":"https://www.joshwcomeau.com/react/usememo-and-usecallback/","videos":{"shortVideo":"https://www.youtube.com/shorts/MyzH0VsQp4Q","longVideo":"https://www.youtube.com/watch?v=YBSt1jYwVfU"},"companies":["Airbnb","Amazon","Apple","Google","Meta","Microsoft","Netflix","Uber"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T05:08:58.383Z","createdAt":"2025-12-23 12:53:08"},{"id":"q-315","question":"How would you optimize a React app's bundle size and loading performance using lazy loading, code splitting, and webpack optimization strategies?","answer":"Implement React.lazy() with Suspense for route splitting, dynamic imports for heavy components, webpack's splitChunks for vendor chunks, and analyze with webpack-bundle-analyzer. Use prefetch/preload for critical paths, service worker caching, and tree shaking to eliminate dead code.","explanation":"## Bundle Optimization Strategy\n\n**Code Splitting Techniques:**\n- Route-based splitting with React.lazy() and Suspense boundaries\n- Component-level splitting for heavy libraries (charts, editors)\n- Webpack's splitChunks configuration for vendor/common chunks\n- Dynamic imports with webpackChunkName for better debugging\n\n**Performance Measurement:**\n- Use webpack-bundle-analyzer to identify large modules\n- Lighthouse performance scores for loading metrics\n- Chrome DevTools Network tab for waterfall analysis\n- Runtime performance monitoring with Web Vitals\n\n**Advanced Optimizations:**\n- Tree shaking with ES modules and sideEffects: false\n- Preload critical resources, prefetch non-critical\n- Service worker with Workbox for caching strategies\n- Compression with Brotli/Gzip and asset minification\n- CDN deployment with edge caching\n\n**Real-world Implementation:**\n```javascript\n// Route splitting\nconst Dashboard = React.lazy(() => import('./Dashboard'));\n\n// Component splitting with chunk naming\nconst Chart = React.lazy(() => \n  import(/* webpackChunkName: \"chart\" */ './Chart')\n);\n\n// Webpack splitChunks config\noptimization: {\n  splitChunks: {\n    chunks: 'all',\n    vendor: {\n      test: /[\\\\/]node_modules[\\\\/]/,\n      name: 'vendors',\n      chunks: 'all'\n    }\n  }\n}\n```\n\n**Key Metrics to Track:**\n- First Contentful Paint (FCP)\n- Largest Contentful Paint (LCP)\n- Time to Interactive (TTI)\n- Bundle size reduction percentages\n- Cache hit ratios","diagram":"flowchart TD\n  A[Start] --> B[End]","difficulty":"intermediate","tags":["lighthouse","bundle","lazy-loading"],"channel":"frontend","subChannel":"react","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-23T06:37:42.650Z","createdAt":"2025-12-23 12:53:10"},{"id":"q-434","question":"You're building a React app with multiple components needing access to user authentication state. When would you choose Context API over Redux, and what are the specific performance implications of each approach?","answer":"Context API is ideal for simple, localized state like authentication or theme that doesn't change frequently. Redux excels for complex state with many actions, time-travel debugging, and middleware ne","explanation":"## Context API vs Redux Decision\n\n### When to Use Context API\n- Authentication state\n- Theme preferences\n- Simple global state\n- Few state updates\n\n### When to Use Redux\n- Complex state logic\n- Many actions/reducers\n- Time-travel debugging needed\n- Middleware requirements\n\n### Performance Considerations\n- Context: All consumers re-render on any change\n- Redux: Selective subscriptions prevent unnecessary renders\n- Context: No additional bundle size\n- Redux: Extra library overhead\n\n### Implementation Example\n```javascript\n// Context API\nconst AuthContext = createContext();\n\n// Redux\nconst store = createStore(authReducer);\n```","diagram":"flowchart TD\n  A[State Management Need] --> B{Simple State?}\n  B -->|Yes| C[Context API]\n  B -->|No| D{Complex Logic?}\n  D -->|Yes| E[Redux]\n  D -->|No| F[Local State]\n  C --> G[Few Updates]\n  E --> H[Many Actions]\n  G --> I[Performance: Good]\n  H --> J[Performance: Optimized]","difficulty":"intermediate","tags":["react","hooks","context","redux"],"channel":"frontend","subChannel":"react","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Microsoft","NVIDIA"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-23T12:42:48.368Z","createdAt":"2025-12-23 12:53:10"},{"id":"q-287","question":"How does a Service Worker intercept network requests and implement offline caching strategies?","answer":"Service Workers register event listeners on 'fetch' events to intercept network requests and can return cached responses using the Cache API.","explanation":"## Why Asked\nTests understanding of Progressive Web Apps and offline functionality implementation.\n## Key Concepts\nService Worker lifecycle, fetch event interception, Cache API strategies (cache-first, network-first), offline-first architecture.\n## Code Example\n```\nself.addEventListener('fetch', event => {\n  event.respondWith(\n    caches.match(event.request)\n      .then(response => response || fetch(event.request))\n  );\n});\n```\n## Follow-up Questions\nWhat are the differences between cache-first vs network-first strategies? How do you handle cache invalidation?","diagram":"flowchart TD\n  A[Network Request] --> B{Service Worker Active?}\n  B -->|Yes| C[Check Cache]\n  C -->|Hit| D[Return Cached Response]\n  C -->|Miss| E[Fetch from Network]\n  E --> F[Cache Response]\n  F --> G[Return Response]\n  B -->|No| E","difficulty":"intermediate","tags":["dom","fetch","websocket","service-worker"],"channel":"frontend","subChannel":"web-apis","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","Meta"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-22T08:36:18.884Z","createdAt":"2025-12-23 12:53:09"},{"id":"q-341","question":"You're building a real-time collaborative document editor. How would you implement a service worker to handle offline synchronization, WebSocket reconnection logic, and conflict resolution when multiple users edit simultaneously?","answer":"Use IndexedDB for offline storage, implement exponential backoff for WebSocket reconnection, and use Operational Transform (OT) for conflict resolution.","explanation":"## Why This Is Asked\nBroadcom needs engineers who can build robust real-time systems that work offline and handle network failures gracefully.\n\n## Expected Answer\nA strong candidate would discuss:\n- Service worker caching strategies (network-first for API, cache-first for assets)\n- IndexedDB for offline document storage\n- WebSocket connection management with exponential backoff\n- Conflict resolution using Operational Transform or CRDTs\n- Background sync API for automatic data upload\n\n## Code Example\n```javascript\n// Service worker with offline sync\nself.addEventListener('sync', (event) => {\n  if (event.tag === 'document-sync') {\n    event.waitUntil(syncDocuments());\n  }\n});\n\nasync function syncDocuments() {\n  const docs = await getOfflineDocuments();\n  for (const doc of docs) {\n    try {\n      await fetch('/api/sync', {\n        method: 'POST',\n        body: JSON.stringify(doc)\n      });\n      await removeOfflineDoc(doc.id);\n    } catch (err) {\n      // Retry on next sync\n      throw err;\n    }\n  }\n}\n\n// WebSocket reconnection with exponential backoff\nclass WebSocketManager {\n  constructor(url) {\n    this.url = url;\n    this.reconnectAttempts = 0;\n    this.maxReconnectAttempts = 5;\n    this.baseDelay = 1000;\n  }\n\n  connect() {\n    this.ws = new WebSocket(this.url);\n    this.ws.onclose = () => this.handleReconnect();\n  }\n\n  handleReconnect() {\n    if (this.reconnectAttempts < this.maxReconnectAttempts) {\n      const delay = this.baseDelay * Math.pow(2, this.reconnectAttempts);\n      setTimeout(() => {\n        this.reconnectAttempts++;\n        this.connect();\n      }, delay);\n    }\n  }\n}\n```","diagram":"flowchart TD\n  A[User edits document] --> B{Online?}\n  B -->|Yes| C[Send via WebSocket]\n  B -->|No| D[Store in IndexedDB]\n  C --> E{Connection lost?}\n  E -->|Yes| F[Queue for background sync]\n  E -->|No| G[Apply OT algorithm]\n  D --> H[Background sync triggers]\n  H --> I[Upload to server]\n  I --> J[Resolve conflicts]\n  J --> K[Update local cache]","difficulty":"advanced","tags":["dom","fetch","websocket","service-worker"],"channel":"frontend","subChannel":"web-apis","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=sFsRylCQblw","longVideo":"https://www.youtube.com/watch?v=ksXwaWHCW6k"},"companies":["Affirm","Broadcom","Roblox"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-23T12:54:00.594Z","createdAt":"2025-12-23 12:53:09"},{"id":"q-419","question":"You're building a real-time food delivery tracking app. How would you implement a WebSocket connection that handles network interruptions and maintains order status updates when the app goes offline?","answer":"Use WebSocket with exponential backoff retry, service worker for offline caching, and IndexedDB for local state persistence.","explanation":"For a real-time delivery tracking app, you need to handle network reliability:\n\n1. **WebSocket Implementation**: Create a WebSocket connection with automatic reconnection using exponential backoff strategy\n2. **Service Worker**: Register a service worker to intercept network requests and cache order data\n3. **Offline Storage**: Use IndexedDB to store order status updates locally when offline\n4. **Sync Strategy**: Implement background sync to push cached updates when connection restores\n5. **State Management**: Maintain optimistic UI updates while confirming with server\n\nKey considerations: connection timeout handling, message queuing, conflict resolution, and battery optimization for mobile devices.","diagram":"flowchart TD\n  A[App Connects] --> B[WebSocket Open]\n  B --> C[Receive Order Updates]\n  C --> D[Update UI Optimistically]\n  D --> E[Store in IndexedDB]\n  E --> F{Network Lost?}\n  F -->|Yes| G[Service Worker Caches]\n  F -->|No| H[Sync with Server]\n  G --> I[Background Sync Queue]\n  I --> J[Network Restored]\n  J --> K[Process Cached Updates]\n  K --> H","difficulty":"intermediate","tags":["dom","fetch","websocket","service-worker"],"channel":"frontend","subChannel":"web-apis","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":"https://www.youtube.com/watch?v=cUGRlM3SZ1w"},"companies":["Apple","DoorDash","MongoDB"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-23T13:30:03.484Z","createdAt":"2025-12-23 12:53:10"},{"id":"q-426","question":"You're building a real-time chat application that needs to work offline. How would you implement a service worker to cache messages and sync them when the user comes back online?","answer":"Implement a service worker with cache-first strategy for messages, use IndexedDB for offline storage, and background sync API. Cache API responses, store new messages in IndexedDB, register sync event","explanation":"## Service Worker Implementation\n\n- Register service worker in main thread with navigator.serviceWorker.register()\n- Install event: cache static assets and initial API responses using caches.open()\n- Fetch event: implement cache-first strategy, try cache first, fallback to network\n- Store new messages in IndexedDB when offline\n- Use Background Sync API to register sync tasks\n\n## Offline Storage Strategy\n\n- IndexedDB for structured message data with timestamps\n- Cache API for immutable responses and static assets\n- Implement message queuing system with retry logic\n- Handle conflict resolution when syncing\n\n## Sync Mechanism\n\n- Register background sync with registration.sync.register('message-sync')\n- Sync event: process queued messages from IndexedDB\n- Implement exponential backoff for failed sync attempts\n- Update UI to show sync status and message delivery state\n\n## Error Handling\n\n- Network state detection with navigator.onLine\n- Graceful degradation when features unavailable\n- User feedback for offline/sync status\n- Cleanup stale cached data periodically","diagram":"flowchart TD\n  A[User sends message] --> B{Network available?}\n  B -->|Yes| C[Send to API]\n  B -->|No| D[Store in IndexedDB]\n  C --> E[Cache response]\n  D --> F[Register background sync]\n  F --> G[Wait for connectivity]\n  G --> H[Sync queued messages]\n  H --> I[Update UI with sync status]\n  E --> J[Update chat interface]","difficulty":"beginner","tags":["dom","fetch","websocket","service-worker"],"channel":"frontend","subChannel":"web-apis","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":"https://www.youtube.com/watch?v=WmR9IMUD_CY"},"companies":["Anthropic","Hugging Face","Snap"],"eli5":null,"relevanceScore":null,"lastUpdated":"2025-12-23T13:34:49.061Z","createdAt":"2025-12-23 12:53:10"}],"subChannels":["css","javascript","performance","react","web-apis"],"companies":["Affirm","Airbnb","Amazon","Anthropic","Apple","Atlassian","Broadcom","Crowdstrike","DE Shaw","Deepmind","Discord","DoorDash","Google","Hrt","Hugging Face","Instacart","LinkedIn","Lyft","Mckinsey","Meta","Microsoft","MongoDB","NVIDIA","Netflix","Okta","Roblox","Salesforce","Scale Ai","Shopify","Snap","Stripe","Uber"],"stats":{"total":30,"beginner":9,"intermediate":11,"advanced":10,"newThisWeek":30}}